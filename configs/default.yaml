# iREPA with Encoder KV Distillation - Default Configuration
# Usage: python train.py --config configs/default.yaml --exp-name my_experiment

# ============================================================================
# Model Configuration
# ============================================================================
model: SiT-B/2-EncoderKV
num-classes: 1000
encoder-depth: 8
fused-attn: true
qk-norm: false
projection-layer-type: conv
proj-kwargs-kernel-size: 1

# ============================================================================
# Encoder KV Configuration
# ============================================================================
enc-type: dinov2-b
enc-layer-indices: "11"     # Encoder layer for K/V extraction (1-based)
sit-layer-indices: "4"     # SiT layer for K/V injection (1-based)
stage1-steps: 30000          # Number of steps for Stage 1
distill-coeff: 2.0          # Coefficient for attention distillation loss

# Alignment mode: logits, attn_mse, kv_mse
align-mode: attn_mse

# K/V projection: linear, mlp, conv
kv-proj-type: linear
kv-proj-kernel-size: 1
kv-norm-type: zscore     # none, layernorm, zscore_spatial, zscore_token, batchnorm
kv-zscore-alpha: 1.0

# ============================================================================
# REPA Loss Configuration
# ============================================================================
repa-loss: true
proj-coeff: "1.0"
projection-loss-type: mse_v    # cosine, mse, mse_v, mse_noisy
spnorm-method: zscore           # none, zscore, zscore_token, layernorm
zscore-alpha: 0.6

# ============================================================================
# Dataset
# ============================================================================
data-dir: /dev/shm/imagenet_repa
resolution: 256
batch-size: 128

# ============================================================================
# Training
# ============================================================================
epochs: 1400
max-train-steps: 400000
checkpointing-steps: 10000
sampling-steps: 100000
gradient-accumulation-steps: 2
learning-rate: 1e-4
adam-beta1: 0.9
adam-beta2: 0.999
adam-weight-decay: 0.0
adam-epsilon: 1e-8
max-grad-norm: 1.0
ema-decay: 0.9999
ema-update-freq: 1

# ============================================================================
# Precision & Performance
# ============================================================================
allow-tf32: true
mixed-precision: fp16
compile: true

# ============================================================================
# Misc
# ============================================================================
seed: 0
num-workers: 12
cfg-prob: 0.1
path-type: linear
prediction: v
n-samples: 256
